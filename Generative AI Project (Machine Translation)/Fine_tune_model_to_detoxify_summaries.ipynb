{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune *toxic-bert* with Reinforcement Learning (PPO) and PEFT to Generate Less-Toxic Summaries for Azerbaijani Langueges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will fine-tune a *toxic-bert* model to generate less toxic content with Meta AI's hate speech reward model. The reward model is a binary classifier that predicts either \"not hate\" or \"hate\" for the given text. You will use Proximal Policy Optimization (PPO) to fine-tune and reduce the model's toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ 1 - Set up Required Dependencies](#1)\n",
    "- [ 2 - Load toxic-bert Model, Prepare Reward Model and Toxicity Evaluator](#2)\n",
    "  - [ 2.1 - Load Data and toxic-bert Model Fine-Tuned with Summarization Instruction](#2.1)\n",
    "  - [ 2.2 - Prepare Reward Model](#2.2)\n",
    "  - [ 2.3 - Evaluate Toxicity](#2.3)\n",
    "- [ 3 - Perform Fine-Tuning to Detoxify the Summaries](#3)\n",
    "  - [ 3.1 - Initialize `PPOTrainer`](#3.1)\n",
    "  - [ 3.2 - Fine-Tune the Model](#3.2)\n",
    "  - [ 3.3 - Evaluate the Model Quantitatively](#3.3)\n",
    "  - [ 3.4 - Evaluate the Model Qualitatively](#3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Set up Required Dependencies\n",
    "\n",
    "Install the required packages to use PyTorch and Hugging Face transformers and datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.17.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (2.17.0)\n",
      "Requirement already satisfied: filelock in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (2.2.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (18.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (0.27.0)\n",
      "Requirement already satisfied: packaging in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets==2.17.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.17.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.17.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.17.0) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.17.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.17.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.17.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.17.0) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets==2.17.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.17.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.17.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.17.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.17.0) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from pandas->datasets==2.17.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from pandas->datasets==2.17.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from pandas->datasets==2.17.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.17.0) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Ignored the following yanked versions: 0.3.0a0\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchdata==0.5.1 (from versions: 0.3.0a1, 0.3.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.8.0, 0.9.0, 0.10.0, 0.10.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchdata==0.5.1\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/lvwerra/trl.git@25fa1bd\n",
      "  Cloning https://github.com/lvwerra/trl.git (to revision 25fa1bd) to /tmp/pip-req-build-6gh671yq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git /tmp/pip-req-build-6gh671yq\n",
      "\u001b[33m  WARNING: Did not find branch or tag '25fa1bd', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q 25fa1bd\n",
      "  Resolved https://github.com/lvwerra/trl.git to commit 25fa1bd\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from trl==0.4.2.dev0) (2.5.1+cu118)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from trl==0.4.2.dev0) (4.27.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from trl==0.4.2.dev0) (2.2.1)\n",
      "Requirement already satisfied: accelerate in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from trl==0.4.2.dev0) (1.2.1)\n",
      "Requirement already satisfied: datasets in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from trl==0.4.2.dev0) (2.17.0)\n",
      "Requirement already satisfied: filelock in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.8.86)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.4.2.dev0) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from accelerate->trl==0.4.2.dev0) (6.1.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from accelerate->trl==0.4.2.dev0) (0.5.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (18.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (3.11.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl==0.4.2.dev0) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.4.2.dev0) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets==2.17.0\n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    peft==0.3.0 --quiet\n",
    "\n",
    "# Installing the Reinforcement Learning library directly from github.\n",
    "%pip install git+https://github.com/lvwerra/trl.git@25fa1bd    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary components. Some of them are new for this week, they will be discussed later in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tqdm library makes the loops show a smart progress meter.\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Load *toxic-bert* Model, Prepare Reward Model and Toxicity Evaluator\n",
    "\n",
    "<a name='2.1'></a>\n",
    "### 2.1 - Load Data and *toxic-bert* Model Fine-Tuned "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will keep working with the same Hugging Face dataset [En-Az](https://huggingface.co/datasets/Zarifa/English-To-Azerbaijani) and the pre-trained model [toxic-bert](https://huggingface.co/unitary/toxic-bert). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 5161\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"Zarifa/English-To-Azerbaijani\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/omniaz/Desktop/jobs/2025/My-Daily-Python-Learning/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Specify the model name\n",
    "model_name = \"unitary/toxic-bert\"\n",
    "\n",
    "# Load the model\n",
    "original_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to preprocess the dataset. I will take only a part of it, then filter the translation of a particular length (just to make those examples long enough and, at the same time, easy to read). Then wrap each sentences with the instruction and tokenize the prompts. Save the token ids in the field `input_ids` and decoded version of the prompts in the field `query`.\n",
    "\n",
    "You could do that all step by step in the cell below, but it is a good habit to organize that all in a function `build_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/5161 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5161/5161 [00:03<00:00, 1616.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Translate the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nTranslate: '\n",
    "    prompt = [start_prompt + sentence + end_prompt for sentence in [ex['aze'] for ex in example['translation']]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer([ex['en'] for ex in example['translation']], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "# The dataset actually contains 3 diff splits: train, validation, test.\n",
    "# The tokenize_function code is handling all data across all splits in batches.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 5161/5161 [00:01<00:00, 2962.30 examples/s]\n",
      "Filter: 100%|██████████| 5161/5161 [00:01<00:00, 3085.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets_training = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)\n",
    "tokenized_datasets_validation = tokenized_datasets.filter(lambda example, index: index % 1001 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a function to pull out the number of model parameters (it is the same as in the Fine Tune LLM for MT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the adapter to the original *toxic-bert* model. I need to pass them to the constructed PEFT model, also putting `is_trainable=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA for the Helsinki model\n",
    "# Dynamically generate the target modules\n",
    "encoder_layers = [f\"model.encoder.layers.{i}.self_attn.{proj}\" for i in range(6) for proj in [\"k_proj\", \"v_proj\", \"q_proj\"]]\n",
    "decoder_self_attn_layers = [f\"model.decoder.layers.{i}.self_attn.{proj}\" for i in range(6) for proj in [\"k_proj\", \"v_proj\", \"q_proj\"]]\n",
    "decoder_cross_attn_layers = [f\"model.decoder.layers.{i}.encoder_attn.{proj}\" for i in range(6) for proj in [\"k_proj\", \"v_proj\", \"q_proj\"]]\n",
    "\n",
    "# Combine all target modules\n",
    "target_modules = encoder_layers + decoder_self_attn_layers + decoder_cross_attn_layers\n",
    "\n",
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rank\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    target_modules=target_modules,  # Explicitly specified target modules\n",
    "    lora_dropout=0.1,  # Dropout for regularization\n",
    "    bias=\"none\",  # No bias reparameterization\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM  # Sequence-to-sequence task\n",
    ")\n",
    "\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(original_model, \n",
    "                                       'peft-sentence-translate-training-1736885736/', \n",
    "                                       lora_config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16, \n",
    "                                       device_map=\"auto\",                                       \n",
    "                                       is_trainable=True)\n",
    "\n",
    "print(f'PEFT model parameters to be updated:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I am preparing to fine-tune the LLM using Reinforcement Learning (RL). RL will be briefly discussed in the next section of this part, but at this stage, I just need to prepare the Proximal Policy Optimization (PPO) model passing the instruct-fine-tuned PEFT model to it. PPO will be used to optimize the RL policy against the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During PPO, only a few parameters will be updated. Specifically, the parameters of the `ValueHead`. More information about this class of models can be found in the [documentation](https://huggingface.co/docs/trl/main/en/models#trl.create_reference_model). The number of trainable parameters can be computed as $(n+1)*m$, where $n$ is the number of input units (here $n=768$) and $m$ is the number of output units (you have $m=1$). The $+1$ term in the equation takes into account the bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a frozen copy of the PPO which will not be fine-tuned - a reference model. The reference model will represent the LLM before detoxification. None of the parameters of the reference model will be updated during PPO training. This is on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "print(f'Reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is set. It is time to prepare the reward model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toxic-bert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
